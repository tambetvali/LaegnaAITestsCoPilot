# Application programming with an Artificial Intelligence

Programming definition: user is asking sensible requests for an AI to generate code. User will participiate in testing with an AI.

Modular programming:
- User is creating Modules and registering them as classes
- User is creating functions and function headers with SpaCy
- User is separating each part of the work into API and body.
- User is creating AI systems to process their tasks

The scalable and distributed modulus is keeping it open for user's inspiration: indeed, I cancelled out the topics which appear very different at various qualifications, or which we keep circulating in head to resolve the fine-tuned, situational or personally constaint aspects: for example, very simple or very advanced program can be programmed by my definitions.

# API and Body

API: a minority of text, which is public. A minority of code service, which is public. A minority of data, which is public, such as public urls and their served content.
Body: a majority of text, which is private. A majority of code back-end, which is private; private variables of class and local indexes and hidden processing of data behind windows and frames. A majority of data, which is private and where user makes a selection about what to expose.

## Simple Markdown Encoding

Template APIBodyPair:

```
%#[/APIBodyPair]#%
%#[/API]#%
# Chapter

Initial input.
%#[API/]#%
%#[/Body]#%
## Subchapter

%#[Body]#%
## Subchapter
%#[/Body]#%
%#[APIBodyPair/]#%
```

This encoding is complicated, but could be generated by an AI from this syntax in intuitive language, with given id, class and thread of processing different structurations separately; a distinct parser and metadata generator, until Q&A generation, woulc be activated. Session-unique identifiers and local, unique codes could turn some parts of metadata into given, local data.

```
# Chapter

AI will know to process this chapter as APIBody pair in thread class APIBodyParsers
%$Create APIBodyPair based on template chapter structure, into it's whole content.$%

You can feed an AI, through fine-tuning or local context / RAG, examples to turn different things to template matches, or this specific template, feeding your examples in statistical average to common statistics, which should resonate optimization and local-interaction flags to keep AI knowledge in order, and match your local acceleration directions of knowledge where thousands of samples can have single, average acceleration constant so that data moves multidimensionally through local samples, but should get balanced force from common distribution to keep proper tilde of the differential angles - gravity, which is applied in iterational steps through back-gradients.

## Subchapter

## Subchapter

## Subchapter
```

### Template Example

You can create template application pattern, which asks to meaningfully use the matching markdown structured data item into form of this template. This is the API.
- This is a function: a function needs a specification body, which lists the formats of tags and other internals, and either keeps the number of internals low or finetunes with successfully solved, manual and automatic tags.

## Character programming

You can use different types of encoding cards or experiments.

You parse the forum, all the discussion with an AI and between users, into threads of cards.

You can make the scanning of surrounding content and execution of machines and scripts working not only in inference, but in training time: in such case, you separate the input and output, make sure the *after* part of content needs the output of machine or tool, and then get your backgradient passive in machine part, only counting the position. This is my ridiculous solution looking solely in simplest spec: make sure how fine-tuning of using tools and their exports is specified in your trainer and fine-tuner.

It's interesting if AI would estimate the answer, but generally you need next tick or card to work with the after-answer; but it's good to get some backgradients there: you can explore pathways for the backgradients to go through moments and estimations, or react differently to different answers.

Now, each "Question" from AI, which is actually answer in the reply card, and "Answer" from the user, which is actually an instruction or question to machine: nice and simple directional "paradox".

Then you need preprogrammed character in training and examples: "Character": You are user. "Question": AI answer. "Answer": User's next question. Based on your training identifier, version or timestamp of session or card, or autogenerated ID in your model's architecture which updates as needed, or just randomness of information and luck of strict connections to be rather patternized: you localize the context.

You see if the character of AI was "Anonymous" or forum's poster name, with forum id/url and ownership stamp/unique username, AI must think they were this user to get the answer based on session.

Sessions and machine to reach surrounding threads and contexts, or other forum topics, can be explored by automation.

Characters:

"You are precise calculator with basic operations and integer numbers on 8-digit screen, Casio standard."

You feed you calculator experiments and estimations.

## Programming

### API

You create a description of what your program does, which will be Instruction field for your AI's configuration: Instruction of how to behave.

This will be used by other AIs, who implement the use cases of your functions and other modules and classes.

### Body

You create specific definitions:
- They can be tasks, each task generates local Q&A card, where AI will use the instruction, along with repeated input or past outputs, for various outputs. This is a set of threads, with forks and joins.

AI can work with data multiple times, and you can ask for database and filesystem requests, which generate requests, file lists and answers before: this way, you can program your automata only with Q&A, where each AI response or first 6 can decide, whether to use installed modules and extensions, which are available in it's scope: defined by headers of the body, or it's API which defines restrictions.

## SpaCy

You learn to create dictionaries with spacy:
- You provide a free-form body of expressions.
- You provide their local, small-in-number, specific counterparts, which act like your standard way of writing it down locally.

The AI character can be that they can only understand the local terms, and you can train this charater of AI.

Between characters, as you train them in mixed, random order of items or samples of the experiment, Q&A cards of each as you get the final format (always Q&A: of functional form and it's output, or the layered matrix and activation stack with knowledge of combinations at each inner step, which you do in iterations and in GPT: chains of layers each working with next letters, tokens, or divisions).

SpaCy learns context-free language most easily: based on it's matching level, assumptions and especially warrancies and solutions. In each domain, you have local context-specific language, which forms it's own local domains: indeed, SpaCy can understand some context, but that's not the central point, because it's not a large-scale, slow AI.

Dictionaries help to connect your tasks.

You make sure your documentation and assessories, such as filesystem trees and notebases:
- Is explored through well-specified tools and features, as well as indexes and file metadata; database and filesystem access as well as access using your intelligent tools, lists or answers, especially specifications and filesystem guides in structured Markdown files, which can themselves be studied.
- Those tools and explorers are available for AI through tool extensions, each approach is a Class or Module you import as dependency and spacy-translated localization of language first-level matching. On this matching, you can generate the most basic fine-tuning cards: once fine-tuned for this dumb matching, it will generate more advanced set of cards itself.
- You also feed Q&A in modified formats, such as "Instruction: Generate Q&A in this form; Answer: Q&A in form you specified.
- You can use training and validation set in random order, where you have two lines in graphs: if both go well, you use the validation cards *after* their use for verification, and assume the function is as more stable in the end as in the beginning; casual nature of it decides - you do so, to decide your architecture in the first half part of training, given half-half decision between training and validation; but you can also build a simple fractal out of this practice.
- You generate AI an examples how to request this exploration, summarize the result based on original intent etc.

## Simulation

Your system allows to generate cards based on:
- You keep history of all AI interaction, and it becomes embedded, trained and finetuned for your character, tone and mode in this conversation, with various degrees of permissions and configured limitations.
- You fix threads: user can choose user mode instead of AI mode, use all the tools and answer the cards with track record in same AI format. This has prolog-form of connection to thread or alternate fork, and it can be marked as fix, another solution, or even wrong solution. The character can be "This user is emulating that he is this AI".

## Code generation

With help of AI:
- You still turn things to more formal, partially DatSu-like-grammar-explorer, partially SpaCy-like-language-pattern-dialector type of solutions, which assumes it's modern-day official: for Spirit to process, rather than dumbest form of calculator, if spirit is about patterns and long-term solutions, rather than the great feeling it provides to living being.
- You ask it to implement HTML or Python widget interfaces.
- You separately create code files for each operation, which will be python executables - you make finally a controller, which runs those executables in order or by complex logic, or uses APIs, hooks, and refactored forks.

## Optimization

API is an optimization:
- Token length and code complexity, even the usage complexity, turns this into exponent length.
- Very short windows, when combined, do not form much of this exponent internally: some 1000 or 1000000 element cycles are what you use in linear fashion, without AI acceleration which occurs in double, exponent space of such little linears (of layer-count-length of some complex, little items).
- It makes your usage seem linear.

This means:
- Basic documentation
- Code access API
- Design usage guide as template, copy-paste or included block, or one assigned to your variable from database and template-item match in addition to the design guide.

Guides are equivalent to design, code, etc.

You need to verify the small code amounts you create in threads: AI must not be obsessed with long conversations.

> Optimization bottleneck is resolved: your exponent complexity needs not to grow into global scale, but you use local exponents in small-scale blocks so that you can also have them more multiplayered; I would also suggest a technique, which linearizes the exponent space upwards, of each separate local space, and grows this area in relatively same manner when spaces are added or multipled - the upwards exponent range is always equal to local range, which is growing through operations - for multiplication, it's growing twice, and for addition, it will be almost the same for two equal spaces and variables.
>
> The optimization appears: APIs are small units, form a local exponent and appear in rather linearized order themselves - so the costy exponent appears rather in row of APIs, than small number of them themselves.
>
> Thus, you need summaries even for summaries: in case they are in longer list, this representation linearizes them.

In AI contexts:
- You use something at all at small-window AI's, and ones with small billions of parameters.
- You use many examples, which are all optimized and accessed by API (mind, general form), specification (body, unrememberable and countable details). They are contained in separate part, which is hidden and not accessed when you work with many items with AI.

You can create memory structure, which allows percents to divide your content window between apis, their summaries and content, and assign variables, with are either set or not set - XML instruction could be used, such as <question> and <answer> -; their sizes and references to memory consumption maps, which can be like class or XML structures or strict templates to follow and to implement with an AI (a template is also class, as it allows to manipulate structures to next form and subsequently run the virtual operations).

## AI time use

Server can provide AI engines, which user can choose to run in server; or thread can provide authorized AI access for those who answer, the same model as in initial request, or web can provide clone models.

User can have an engine in browser or run it locally, providing their local server IP and port to the online system, which uses their AI and provides responses of tools, tool access lists (toolset documented APIs) etc.

User can provide API keys to use external systems, such as CoPilot, ChatGPT or a custom Ollama model.

Each thread can either set these as constraints, or leave the choices open to user or their permission system.

This is basically each imaginable access in this basic class.
